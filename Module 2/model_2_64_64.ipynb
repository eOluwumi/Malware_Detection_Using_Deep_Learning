{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sgd=optimizers.SGD(lr=0.0000001 ,decay=0.0000001/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(64, 64, 1...)`\n",
      "  \n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(.25))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator()\n",
    "# test_datagen = ImageDataGenerator()\n",
    "all_images = []\n",
    "y_train=[]\n",
    "ctr = 0\n",
    "for image_path in listdir('training_set/benign/'): \n",
    "    img = Image.open('training_set/benign/' + image_path)\n",
    "#     img_class, img_name, ext = image_path.split('.')\n",
    "#     img = img.resize((32, 32))\n",
    "    img = np.array(img)\n",
    "#     print(img.shape)\n",
    "    all_images.append(img)\n",
    "    y_train.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images = []\n",
    "# y_train = []\n",
    "for image_path in listdir('training_set/malware/'): \n",
    "    img = Image.open('training_set/malware/' + image_path)\n",
    "#     img = img.resize((32, 32))\n",
    "    img = np.array(img)\n",
    "    all_images.append(img)\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = train_datagen.flow_from_directory('/training_set/', target_size=(32, 32), batch_size=1, class_mode='binary')\n",
    "# test_set = test_datagen.flow_from_directory('/test_set/', target_size=(32, 32), batch_size=1, class_mode='binary')\n",
    "all_images = np.array(all_images).reshape(199, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.1321 - acc: 0.9619 - val_loss: 8.6080e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to 64_2_temp_weights_01_1.00.hdf5\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 4s 41ms/step - loss: 0.0915 - acc: 0.9714 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.1143 - acc: 0.9619 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 4s 41ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.0644 - acc: 0.9810 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 4s 41ms/step - loss: 0.1489 - acc: 0.9619 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.1007 - acc: 0.9714 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.0891 - acc: 0.9810 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 4s 40ms/step - loss: 0.1083 - acc: 0.9619 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d49dff8ac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='64_2_temp_weights_{epoch:02d}_{val_acc:.2f}.hdf5', verbose=1, monitor='val_acc', save_best_only=True, mode='max')\n",
    "model.fit(x=all_images, y=np.array(y_train),batch_size=10, epochs=10, validation_split=0.1, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 6,463,681\n",
      "Trainable params: 6,462,401\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_2_64_64_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_weights\n",
    "model.load_weights('model_2_64_64/64_2_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = image.load_img('training_set/self_benign/com.dsi.ant.service.socket-40700.apk.bmp', target_size=(64, 64))\n",
    "# test_image = image.img_to_array(test)\n",
    "# test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "img = Image.open('test_set/malware/0e0bca61b13b24e4fecfc715b67908813c411aab63519173e277f76cec117044.apk.png')\n",
    "#     img = img.resize((32, 32))\n",
    "img = np.array(img)\n",
    "img = np.array(img).reshape(1, 64, 64, 1)\n",
    "result = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malware\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "if (result[0][0] < 0.5):\n",
    "    print(\"benign\")\n",
    "else:\n",
    "    print(\"malware\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
