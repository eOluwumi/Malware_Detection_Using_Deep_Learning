{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir\n",
    "from scipy import misc\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sgd=optimizers.SGD(lr=0.0000001 ,decay=0.0000001/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(64, 64, 1...)`\n",
      "  \n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator()\n",
    "# test_datagen = ImageDataGenerator()\n",
    "all_images = []\n",
    "y_train=[]\n",
    "ctr = 0\n",
    "for image_path in listdir('training_set/benign/'): \n",
    "    img = Image.open('training_set/benign/' + image_path)\n",
    "#     img_class, img_name, ext = image_path.split('.')\n",
    "#     img = img.resize((32, 32))\n",
    "    img = np.array(img)\n",
    "#     print(img.shape)\n",
    "    all_images.append(img)\n",
    "    y_train.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images = []\n",
    "# y_train = []\n",
    "for image_path in listdir('training_set/malware/'): \n",
    "    img = Image.open('training_set/malware/' + image_path)\n",
    "#     img = img.resize((32, 32))\n",
    "    img = np.array(img)\n",
    "    all_images.append(img)\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = train_datagen.flow_from_directory('/training_set/', target_size=(32, 32), batch_size=1, class_mode='binary')\n",
    "# test_set = test_datagen.flow_from_directory('/test_set/', target_size=(32, 32), batch_size=1, class_mode='binary')\n",
    "all_images = np.array(all_images).reshape(199, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 179 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 8s 45ms/step - loss: 0.1185 - acc: 0.9609 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to small_64_siddhanth_weights_01_1.00.hdf5\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0633 - acc: 0.9888 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0267 - acc: 0.9888 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 7.0322e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 4.7644e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0245 - acc: 0.9944 - val_loss: 2.5896e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0476 - acc: 0.9944 - val_loss: 2.2800e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 6s 35ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.5919e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ba07a7278>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='small_64_siddhanth_weights_{epoch:02d}_{val_acc:.2f}.hdf5', verbose=1, monitor='val_acc', save_best_only=True, mode='max')\n",
    "model.fit(x=all_images, y=np.array(y_train),batch_size=10, epochs=10, validation_split=0.1, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,257,985\n",
      "Trainable params: 1,256,577\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_3_64_64_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_weights\n",
    "model.load_weights('model_3_64_64/64_3_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = image.load_img('training_set/self_benign/com.dsi.ant.service.socket-40700.apk.bmp', target_size=(64, 64))\n",
    "# test_image = image.img_to_array(test)\n",
    "# test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "img = Image.open('test_set/malware/0e0bca61b13b24e4fecfc715b67908813c411aab63519173e277f76cec117044.apk.png')\n",
    "#     img = img.resize((32, 32))\n",
    "img = np.array(img)\n",
    "img = np.array(img).reshape(1, 64, 64, 1)\n",
    "result = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "if (result[0][0] < 0.5):\n",
    "    print(\"benign\")\n",
    "else:\n",
    "    print(\"malware\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
